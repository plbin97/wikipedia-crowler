<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Monte Carlo tree search - Wikipedia</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Monte_Carlo_tree_search","wgTitle":"Monte Carlo tree search","wgCurRevisionId":883198123,"wgRevisionId":883198123,"wgArticleId":40528449,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 maint: Uses authors parameter","All articles with dead external links","Articles with dead external links from February 2018","Articles with permanently dead external links","CS1 maint: Multiple names: authors list","All articles with unsourced statements","Articles with unsourced statements from December 2016","Combinatorial game theory","Heuristic algorithms","Monte Carlo methods","Optimal decisions"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Monte_Carlo_tree_search","wgRelevantArticleId":40528449,"wgRequestId":"XGSRjwpAME8AAESegDQAAAAK","wgCSPNonce":false,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{}},"wgStableRevisionId":null,"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgWikiEditorEnabledModules":[],"wgBetaFeaturesFeatures":[],"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsShouldSendModuleToUser":true,"wgPopupsConflictsWithNavPopupGadget":false,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en","usePageImages":true,"usePageDescriptions":true},"wgMFIsPageContentModelEditable":true,"wgMFExpandAllSectionsUserOption":true,"wgMFEnableFontChanger":true,"wgMFDisplayWikibaseDescriptions":{"search":true,"nearby":true,"watchlist":true,"tagline":false},"wgRelatedArticles":null,"wgRelatedArticlesUseCirrusSearch":true,"wgRelatedArticlesOnlyUseCirrusSearch":false,"wgWMESchemaEditAttemptStepOversample":false,"wgPoweredByHHVM":true,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralNoticeCookiesToDelete":[],"wgCentralNoticeCategoriesUsingLegacy":["Fundraising","fundraising"],"wgWikibaseItemId":"Q11785332","wgScoreNoteLanguages":{"arabic":"العربية","catalan":"català","deutsch":"Deutsch","english":"English","espanol":"español","italiano":"italiano","nederlands":"Nederlands","norsk":"norsk","portugues":"português","suomi":"suomi","svenska":"svenska","vlaams":"West-Vlams"},"wgScoreDefaultNoteLanguage":"nederlands","wgCentralAuthMobileDomain":false,"wgCodeMirrorEnabled":true,"wgVisualEditorToolbarScrollOffset":0,"wgVisualEditorUnsupportedEditParams":["undo","undoafter","veswitched"],"wgEditSubmitButtonLabelPublish":true,"oresWikiId":"enwiki","oresBaseUrl":"http://ores.discovery.wmnet:8081/","oresApiVersion":3});mw.loader.state({"ext.gadget.charinsert-styles":"ready","ext.globalCssJs.user.styles":"ready","ext.globalCssJs.site.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","ext.globalCssJs.site":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"});mw.loader.implement("user.tokens@0tffind",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.eventlogger","ext.uls.init","ext.uls.compactlinks","ext.uls.interface","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"];mw.loader.load(RLPAGEMODULES);});</script>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector"/>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.33.0-wmf.16"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Monte_Carlo_tree_search"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Monte_Carlo_tree_search rootpage-Monte_Carlo_tree_search skin-vector action-view">		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>
			<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div><div class="mw-indicators mw-body-content">
</div>
<h1 id="firstHeading" class="firstHeading" lang="en">Monte Carlo tree search</h1>			<div id="bodyContent" class="mw-body-content">
				<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>				<div id="contentSub"></div>
				<div id="jump-to-nav"></div>				<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
				<a class="mw-jump-link" href="#p-search">Jump to search</a>
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><table class="infobox" style="width:22em"><caption>Monte Carlo tree search</caption><tbody><tr><th scope="row">Class</th><td><a href="/wiki/Search_algorithm" title="Search algorithm">Search algorithm</a></td></tr></tbody></table>
<table class="vertical-navbox nowraplinks hlist" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Graph_traversal" title="Graph traversal">Graph</a> and <a href="/wiki/Tree_traversal" title="Tree traversal">tree<br />search algorithms</a></th></tr><tr><td style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Alpha%E2%80%93beta_pruning" title="Alpha–beta pruning">α–β</a></li>
<li><a href="/wiki/A*_search_algorithm" title="A* search algorithm">A*</a></li>
<li><a href="/wiki/B*" title="B*">B*</a></li>
<li><a href="/wiki/Backtracking" title="Backtracking">Backtracking</a></li>
<li><a href="/wiki/Beam_search" title="Beam search">Beam</a></li>
<li><a href="/wiki/Bellman%E2%80%93Ford_algorithm" title="Bellman–Ford algorithm">Bellman–Ford</a></li>
<li><a href="/wiki/Best-first_search" title="Best-first search">Best-first</a></li>
<li><a href="/wiki/Bidirectional_search" title="Bidirectional search">Bidirectional</a></li>
<li><a href="/wiki/Bor%C5%AFvka%27s_algorithm" title="Borůvka&#39;s algorithm">Borůvka</a></li>
<li><a href="/wiki/Branch_and_bound" title="Branch and bound">Branch &amp; bound</a></li>
<li><a href="/wiki/Breadth-first_search" title="Breadth-first search">BFS</a></li>
<li><a href="/wiki/British_Museum_algorithm" title="British Museum algorithm">British Museum</a></li>
<li><a href="/wiki/D*" title="D*">D*</a></li>
<li><a href="/wiki/Depth-first_search" title="Depth-first search">DFS</a></li>
<li><a href="/wiki/Dijkstra%27s_algorithm" title="Dijkstra&#39;s algorithm">Dijkstra</a></li>
<li><a href="/wiki/Edmonds%27_algorithm" title="Edmonds&#39; algorithm">Edmonds</a></li>
<li><a href="/wiki/Floyd%E2%80%93Warshall_algorithm" title="Floyd–Warshall algorithm">Floyd–Warshall</a></li>
<li><a href="/wiki/Fringe_search" title="Fringe search">Fringe search</a></li>
<li><a href="/wiki/Hill_climbing" title="Hill climbing">Hill climbing</a></li>
<li><a href="/wiki/Iterative_deepening_A*" title="Iterative deepening A*">IDA*</a></li>
<li><a href="/wiki/Iterative_deepening_depth-first_search" title="Iterative deepening depth-first search">Iterative deepening</a></li>
<li><a href="/wiki/Johnson%27s_algorithm" title="Johnson&#39;s algorithm">Johnson</a></li>
<li><a href="/wiki/Jump_point_search" title="Jump point search">Jump point</a></li>
<li><a href="/wiki/Kruskal%27s_algorithm" title="Kruskal&#39;s algorithm">Kruskal</a></li>
<li><a href="/wiki/Lexicographic_breadth-first_search" title="Lexicographic breadth-first search">Lexicographic BFS</a></li>
<li><a href="/wiki/Lifelong_Planning_A*" title="Lifelong Planning A*">LPA*</a></li>
<li><a href="/wiki/Prim%27s_algorithm" title="Prim&#39;s algorithm">Prim</a></li>
<li><a href="/wiki/SMA*" title="SMA*">SMA*</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Listings</th></tr><tr><td style="padding:0 0.1em 0.4em">
<ul><li><i><a href="/wiki/Category:Graph_algorithms" title="Category:Graph algorithms">Graph algorithms</a></i></li>
<li><i><a href="/wiki/Category:Search_algorithms" title="Category:Search algorithms">Search algorithms</a></i></li>
<li><i><a href="/wiki/List_of_algorithms#Graph_algorithms" title="List of algorithms">List of graph algorithms</a></i></li></ul></td>
</tr><tr><th style="padding:0.1em">
Related topics</th></tr><tr><td style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Dynamic_programming" title="Dynamic programming">Dynamic programming</a></li>
<li><a href="/wiki/Graph_traversal" title="Graph traversal">Graph traversal</a></li>
<li><a href="/wiki/Tree_traversal" title="Tree traversal">Tree traversal</a></li>
<li><a href="/wiki/Search_game" title="Search game">Search games</a></li></ul></td>
</tr><tr><td style="text-align:right;font-size:115%"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Graph_search_algorithm" title="Template:Graph search algorithm"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Graph_search_algorithm" title="Template talk:Graph search algorithm"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Graph_search_algorithm&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p>In <a href="/wiki/Computer_science" title="Computer science">computer science</a>, <b>Monte Carlo tree search</b> (<b>MCTS</b>) is a <a href="/wiki/Heuristic_(computer_science)" title="Heuristic (computer science)">heuristic</a> <a href="/wiki/Search_algorithm" title="Search algorithm">search algorithm</a> for some kinds of <a href="/wiki/Decision_process" class="mw-redirect" title="Decision process">decision processes</a>, most notably those employed in game play. MCTS has been used for decades in <a href="/wiki/Computer_Go" title="Computer Go">computer Go</a> programs.<sup id="cite_ref-alphago_1-0" class="reference"><a href="#cite_note-alphago-1">&#91;1&#93;</a></sup> It has been used in other board games like <a href="/wiki/Chess" title="Chess">chess</a> and <a href="/wiki/Shogi" title="Shogi">shogi</a>,<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup> games with incomplete information such as <a href="/wiki/Contract_bridge" title="Contract bridge">bridge</a><sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup> and <a href="/wiki/Poker" title="Poker">poker</a>,<sup id="cite_ref-cpr_4-0" class="reference"><a href="#cite_note-cpr-4">&#91;4&#93;</a></sup> as well as in real-time video games (such as <a href="/wiki/Total_War:_Rome_II" title="Total War: Rome II">Total War: Rome II</a>'s implementation in the high level campaign AI<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup>).
</p>
<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Principle_of_operation"><span class="tocnumber">2</span> <span class="toctext">Principle of operation</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Pure_Monte_Carlo_game_search"><span class="tocnumber">3</span> <span class="toctext">Pure Monte Carlo game search</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Exploration_and_exploitation"><span class="tocnumber">4</span> <span class="toctext">Exploration and exploitation</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Advantages_and_disadvantages"><span class="tocnumber">5</span> <span class="toctext">Advantages and disadvantages</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Improvements"><span class="tocnumber">6</span> <span class="toctext">Improvements</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#See_also"><span class="tocnumber">7</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-8"><a href="#References"><span class="tocnumber">8</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#Bibliography"><span class="tocnumber">9</span> <span class="toctext">Bibliography</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The <a href="/wiki/Monte_Carlo_method" title="Monte Carlo method">Monte Carlo method</a>, which uses randomness for deterministic problems difficult or impossible to solve using other approaches, dates back to the 1940s. Bruce Abramson explored the MCTS idea in his 1987 PhD thesis and said it "is shown to be precise, accurate, easily estimable, efficiently calculable, and domain-independent."<sup id="cite_ref-Abramson_6-0" class="reference"><a href="#cite_note-Abramson-6">&#91;6&#93;</a></sup>  He experimented in-depth with <a href="/wiki/Tic-tac-toe" title="Tic-tac-toe">Tic-tac-toe</a> and then with machine-generated evaluation functions for <a href="/wiki/Reversi" title="Reversi">Othello</a> and <a href="/wiki/Chess" title="Chess">Chess</a>.
</p><p>Such methods were then explored and successfully applied to heuristic search in the field of <a href="/wiki/Automated_theorem_proving" title="Automated theorem proving">automated theorem proving</a> by W. Ertel, J. Schumann and C. Suttner in 1989,<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup><sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup><sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup> thus improving the exponential search times of uninformed search algorithms such as e.g. breadth-first search, depth-first search or <a href="/wiki/Iterative_deepening" class="mw-redirect" title="Iterative deepening">iterative deepening</a>.
</p><p>In 1992, B. Brügmann employed it for the first time in a <a href="/wiki/Computer_Go" title="Computer Go">Go-playing program</a>.<sup id="cite_ref-Bruegmann_10-0" class="reference"><a href="#cite_note-Bruegmann-10">&#91;10&#93;</a></sup> Chang et al.<sup id="cite_ref-Chang2005_11-0" class="reference"><a href="#cite_note-Chang2005-11">&#91;11&#93;</a></sup> proposed the idea of "recursive rolling out and backtracking" with "adaptive" sampling choices in their Adaptive Multi-stage Sampling (AMS) algorithm for the model of Markov decision processes. (AMS was the first work to explore the idea of UCB-based exploration and exploitation in constructing sampled/simulated (Monte Carlo) trees and was the main seed for UCT.<sup id="cite_ref-changORMStoday_12-0" class="reference"><a href="#cite_note-changORMStoday-12">&#91;12&#93;</a></sup>)
</p>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Computer-go-ratings-English.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Computer-go-ratings-English.svg/220px-Computer-go-ratings-English.svg.png" decoding="async" width="220" height="155" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Computer-go-ratings-English.svg/330px-Computer-go-ratings-English.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Computer-go-ratings-English.svg/440px-Computer-go-ratings-English.svg.png 2x" data-file-width="493" data-file-height="347" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Computer-go-ratings-English.svg" class="internal" title="Enlarge"></a></div>The rating of best Go-playing programs on the KGS server since 2007. Since 2006, all the best programs use Monte Carlo tree search.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup></div></div></div>
<p>In 2006, inspired by these predecessors,<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup> <a href="/wiki/R%C3%A9mi_Coulom" title="Rémi Coulom">Rémi Coulom</a> described the application of the Monte Carlo method to game-tree search and coined the name Monte Carlo tree search,<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;15&#93;</a></sup> L. Kocsis and Cs. Szepesvári developed the UCT algorithm,<sup id="cite_ref-Kocsis-Szepesvari_16-0" class="reference"><a href="#cite_note-Kocsis-Szepesvari-16">&#91;16&#93;</a></sup> and S. Gelly et al. implemented UCT in their program MoGo.<sup id="cite_ref-Gelly-et-al_17-0" class="reference"><a href="#cite_note-Gelly-et-al-17">&#91;17&#93;</a></sup> In 2008, MoGo achieved <a href="/wiki/Dan_(rank)" title="Dan (rank)">dan</a> (master) level in 9×9 Go,<sup id="cite_ref-18" class="reference"><a href="#cite_note-18">&#91;18&#93;</a></sup> and the Fuego program began to win with strong amateur players in 9×9 Go.<sup id="cite_ref-19" class="reference"><a href="#cite_note-19">&#91;19&#93;</a></sup>
</p><p>In January 2012, the Zen program won 3:1 in a Go match on a 19×19 board with an <a href="/wiki/Go_ranks_and_ratings" title="Go ranks and ratings">amateur 2 dan</a> player.<sup id="cite_ref-20" class="reference"><a href="#cite_note-20">&#91;20&#93;</a></sup> <a href="/wiki/Google_DeepMind" class="mw-redirect" title="Google DeepMind">Google Deepmind</a> developed the program <a href="/wiki/AlphaGo" title="AlphaGo">AlphaGo</a>, which in October 2015 became the first Computer Go program to beat a professional human Go player without <a href="/wiki/Go_handicaps" class="mw-redirect" title="Go handicaps">handicaps</a> on a full-sized 19x19 board.<sup id="cite_ref-alphago_1-1" class="reference"><a href="#cite_note-alphago-1">&#91;1&#93;</a></sup><sup id="cite_ref-21" class="reference"><a href="#cite_note-21">&#91;21&#93;</a></sup><sup id="cite_ref-22" class="reference"><a href="#cite_note-22">&#91;22&#93;</a></sup> In March 2016, AlphaGo was awarded an honorary 9-dan (master) level in 19×19 Go for defeating Lee Sedol in <a href="/wiki/AlphaGo_versus_Lee_Sedol" title="AlphaGo versus Lee Sedol">a five-game match</a> with a final score of four games to one.<sup id="cite_ref-23" class="reference"><a href="#cite_note-23">&#91;23&#93;</a></sup> AlphaGo represents a significant improvement over previous Go programs as well as a milestone in <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> as it uses Monte Carlo tree search with <a href="/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural networks</a> (a <a href="/wiki/Deep_learning" title="Deep learning">deep learning</a> method) for policy (move selection) and value, giving it efficiency far surpassing previous programs.<sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup>
</p><p>Monte Carlo tree search has also been used in programs that play other <a href="/wiki/Board_game" title="Board game">board games</a> (for example <a href="/wiki/Hex_(board_game)" title="Hex (board game)">Hex</a>,<sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup> <a href="/wiki/Havannah" title="Havannah">Havannah</a>,<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup> <a href="/wiki/Game_of_the_Amazons" title="Game of the Amazons">Game of the Amazons</a>,<sup id="cite_ref-27" class="reference"><a href="#cite_note-27">&#91;27&#93;</a></sup> and <a href="/wiki/Arimaa" title="Arimaa">Arimaa</a><sup id="cite_ref-28" class="reference"><a href="#cite_note-28">&#91;28&#93;</a></sup>), real-time video games (for instance <a href="/wiki/Ms._Pac-Man" title="Ms. Pac-Man">Ms. Pac-Man</a><sup id="cite_ref-29" class="reference"><a href="#cite_note-29">&#91;29&#93;</a></sup><sup id="cite_ref-30" class="reference"><a href="#cite_note-30">&#91;30&#93;</a></sup> and <a href="/wiki/Fable_Legends" title="Fable Legends">Fable Legends</a><sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (December 2016)">citation needed</span></a></i>&#93;</sup>), and nondeterministic games (such as <a href="/wiki/Skat_(card_game)" title="Skat (card game)">skat</a>,<sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;31&#93;</a></sup> <a href="/wiki/Poker" title="Poker">poker</a>,<sup id="cite_ref-cpr_4-1" class="reference"><a href="#cite_note-cpr-4">&#91;4&#93;</a></sup> <a href="/wiki/Magic:_The_Gathering" title="Magic: The Gathering">Magic: The Gathering</a>,<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">&#91;32&#93;</a></sup> or <a href="/wiki/Settlers_of_Catan" class="mw-redirect" title="Settlers of Catan">Settlers of Catan</a><sup id="cite_ref-33" class="reference"><a href="#cite_note-33">&#91;33&#93;</a></sup>).
</p>
<h2><span class="mw-headline" id="Principle_of_operation">Principle of operation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=2" title="Edit section: Principle of operation">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The focus of Monte Carlo tree search is on the analysis of the most promising moves, expanding the <a href="/wiki/Search_tree" title="Search tree">search tree</a> based on <a href="/wiki/Monte_Carlo_method" title="Monte Carlo method">random sampling</a> of the search space.
The application of Monte Carlo tree search in games is based on many <i>playouts</i>. In each playout, the game is played out to the very end by selecting moves at random. The final game result of each playout is then used to weight the nodes in the game tree so that better nodes are more likely to be chosen in future playouts.
</p><p>The most basic way to use playouts is to apply the same number of playouts after each legal move of the current player, then choose the move which led to the most victories.<sup id="cite_ref-Bruegmann_10-1" class="reference"><a href="#cite_note-Bruegmann-10">&#91;10&#93;</a></sup> The efficiency of this method—called <i>Pure Monte Carlo Game Search</i>—often increases with time as more playouts are assigned to the moves that have frequently resulted in the current player's victory according to previous playouts. Each round of Monte Carlo tree search consists of four steps:<sup id="cite_ref-chaslot2008_34-0" class="reference"><a href="#cite_note-chaslot2008-34">&#91;34&#93;</a></sup>
</p>
<ul><li><i>Selection</i>: start from root <span class="texhtml"><i>R</i></span> and select successive child nodes until a leaf node <span class="texhtml"><i>L</i></span> is reached. The root is the current game state and a leaf is any node from which no simulation (playout) has yet been initiated. The section below says more about a way of biasing choice of child nodes that lets the game tree expand towards the most promising moves, which is the essence of Monte Carlo tree search.</li>
<li><i>Expansion</i>: unless <span class="texhtml"><i>L</i></span> ends the game decisively (e.g. win/loss/draw) for either player, create one (or more) child nodes and choose node <span class="texhtml"><i>C</i></span> from one of them. Child nodes are any valid moves from the game position defined by <span class="texhtml"><i>L</i></span>.</li>
<li><i>Simulation</i>: complete one random playout from node <span class="texhtml"><i>C</i></span>. This step is sometimes also called playout or rollout. A playout may be as simple as choosing <a href="/wiki/Discrete_uniform_distribution" title="Discrete uniform distribution">uniform random</a> moves until the game is decided (for example in chess, the game is won, lost, or drawn).</li>
<li><i>Backpropagation</i>: use the result of the playout to update information in the nodes on the path from <span class="texhtml"><i>C</i></span> to <span class="texhtml"><i>R</i></span>.</li></ul>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:810px;"><a href="/wiki/File:MCTS_(English)_-_Updated_2017-11-19.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/6/62/MCTS_%28English%29_-_Updated_2017-11-19.svg/808px-MCTS_%28English%29_-_Updated_2017-11-19.svg.png" decoding="async" width="808" height="270" class="thumbimage" data-file-width="808" data-file-height="270" /></a>  <div class="thumbcaption">Steps of Monte Carlo tree search</div></div></div></div>
<p>This graph shows the steps involved in one decision, with each node showing the ratio of wins to total playouts from that point in the game tree for the player that node represents.<sup id="cite_ref-35" class="reference"><a href="#cite_note-35">&#91;35&#93;</a></sup> In the Selection diagram, black is about to move. The root node shows there are 11 wins out of 21 playouts for white from this position so far. It complements the total of 10/21 black wins shown along the three black nodes under it, each of which represents a possible black move.
</p><p>If white loses the simulation, all nodes along the selection incremented their simulation count (the denominator), but among them only the black nodes were credited with wins (the numerator). If instead white wins, all nodes along the selection would still increment their simulation count, but among them only the white nodes would be credited with wins. In games where draws are possible, a draw causes the numerator for both black and white to be incremented by 0.5 and the denominator by 1. This ensures that during selection, each player's choices expand towards the most promising moves for that player, which mirrors the goal of each player to maximize the value of their move.
</p><p>Rounds of search are repeated as long as the time allotted to a move remains. Then the move with the most simulations made (i.e. the highest denominator) is chosen as the final answer.
</p>
<h2><span class="mw-headline" id="Pure_Monte_Carlo_game_search">Pure Monte Carlo game search</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=3" title="Edit section: Pure Monte Carlo game search">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>This basic procedure can be applied to any game whose positions necessarily have a finite number of moves and finite length. For each position, all feasible moves are determined: <i>k</i> random games are played out to the very end, and the scores are recorded. The move leading to the best score is chosen. Ties are broken by fair coin flips. Pure Monte Carlo Game Search results in strong play in several games with random elements, as in the game <i><a href="/wiki/EinStein_w%C3%BCrfelt_nicht!" title="EinStein würfelt nicht!">EinStein würfelt nicht!</a></i>. It converges to optimal play (as <i>k</i> tends to infinity) in board filling games with random turn order, for instance in <a href="/wiki/Hex_(board_game)" title="Hex (board game)">Hex</a> with random turn order.<sup id="cite_ref-36" class="reference"><a href="#cite_note-36">&#91;36&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Exploration_and_exploitation">Exploration and exploitation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=4" title="Edit section: Exploration and exploitation">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The main difficulty in selecting child nodes is maintaining some balance between the <i>exploitation</i> of deep variants after moves with high average win rate and the <i>exploration</i> of moves with few simulations. The first formula for balancing exploitation and exploration in games, called UCT (<i>Upper Confidence Bound</i> 1 <i>applied to trees</i>), was introduced by <a href="/w/index.php?title=Levente_Kocsis&amp;action=edit&amp;redlink=1" class="new" title="Levente Kocsis (page does not exist)">Levente Kocsis</a> and <a href="/w/index.php?title=Csaba_Szepesv%C3%A1ri&amp;action=edit&amp;redlink=1" class="new" title="Csaba Szepesvári (page does not exist)">Csaba Szepesvári</a>.<sup id="cite_ref-Kocsis-Szepesvari_16-1" class="reference"><a href="#cite_note-Kocsis-Szepesvari-16">&#91;16&#93;</a></sup> UCT is based on the UCB1 formula derived by Auer, Cesa-Bianchi, and Fischer<sup id="cite_ref-37" class="reference"><a href="#cite_note-37">&#91;37&#93;</a></sup> and the provably convergent AMS (Adaptive Multi-stage Sampling) algorithm first applied to multi-stage decision making models (specifically, <a href="/wiki/Markov_Decision_Processes" class="mw-redirect" title="Markov Decision Processes">Markov Decision Processes</a>) by Chang, Fu, Hu, and Marcus.<sup id="cite_ref-Chang2005_11-1" class="reference"><a href="#cite_note-Chang2005-11">&#91;11&#93;</a></sup> Kocsis and Szepesvári recommend to choose in each node of the game tree the move for which the expression <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\frac {w_{i}}{n_{i}}}+c{\sqrt {\frac {\ln N_{i}}{n_{i}}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <msub>
              <mi>w</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <msub>
              <mi>n</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mfrac>
        </mrow>
        <mo>+</mo>
        <mi>c</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <msqrt>
            <mfrac>
              <mrow>
                <mi>ln</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <msub>
                  <mi>N</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
              </mrow>
              <msub>
                <mi>n</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
            </mfrac>
          </msqrt>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\frac {w_{i}}{n_{i}}}+c{\sqrt {\frac {\ln N_{i}}{n_{i}}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b607bd848f08876b247148bad27c3c26a1066a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.171ex; width:15.299ex; height:7.676ex;" alt="{\displaystyle {\frac {w_{i}}{n_{i}}}+c{\sqrt {\frac {\ln N_{i}}{n_{i}}}}}"/></span> has the highest value. In this formula:
</p>
<ul><li><span class="texhtml"><i>w</i><sub><i>i</i></sub></span> stands for the number of wins for the node considered after the <span class="texhtml"><i>i</i></span>-th move</li>
<li><span class="texhtml"><i>n</i><sub><i>i</i></sub></span> stands for the number of simulations for the node considered after the <span class="texhtml"><i>i</i></span>-th move</li>
<li><span class="texhtml"><i>N</i><sub><i>i</i></sub></span> stands for the total number of simulations after the <span class="texhtml"><i>i</i></span>-th move</li>
<li><span class="texhtml"><i>c</i></span> is the exploration parameter—theoretically equal to <span class="texhtml"><span class="nowrap">&#8730;<span style="border-top:1px solid; padding:0 0.1em;">2</span></span></span>; in practice usually chosen empirically</li></ul>
<p>The first component of the formula above corresponds to exploitation; it is high for moves with high average win ratio. The second component corresponds to exploration; it is high for moves with few simulations.
</p><p>Most contemporary implementations of Monte Carlo tree search are based on some variant of UCT that traces its roots back to the AMS simulation optimization algorithm for estimating the value function in finite-horizon <a href="/wiki/Markov_Decision_Processes" class="mw-redirect" title="Markov Decision Processes">Markov Decision Processes</a> (MDPs) introduced by Chang et al.<sup id="cite_ref-Chang2005_11-2" class="reference"><a href="#cite_note-Chang2005-11">&#91;11&#93;</a></sup> (2005) in <a href="/wiki/Operations_Research" class="mw-redirect" title="Operations Research">Operations Research</a>. (AMS was the first work to explore the idea of UCB-based exploration and exploitation in constructing sampled/simulated (Monte Carlo) trees and was the main seed for UCT.<sup id="cite_ref-changORMStoday_12-1" class="reference"><a href="#cite_note-changORMStoday-12">&#91;12&#93;</a></sup>)
</p>
<h2><span class="mw-headline" id="Advantages_and_disadvantages">Advantages and disadvantages</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=5" title="Edit section: Advantages and disadvantages">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Although it has been proven that the evaluation of moves in Monte Carlo tree search converges to <a href="/wiki/Minimax" title="Minimax">minimax</a>,<sup id="cite_ref-38" class="reference"><a href="#cite_note-38">&#91;38&#93;</a></sup> the basic version of Monte Carlo tree search converges very slowly. However Monte Carlo tree search does offer significant advantages over <a href="/wiki/Alpha%E2%80%93beta_pruning" title="Alpha–beta pruning">alpha–beta pruning</a> and similar algorithms that minimize the search space.
</p><p>In particular, Monte Carlo tree search does not need an explicit <a href="/wiki/Evaluation_function" title="Evaluation function">evaluation function</a>. Simply implementing the game's mechanics is sufficient to explore the search space (i.e. the generating of allowed moves in a given position and the game-end conditions). As such, Monte Carlo tree search can be employed in games without a developed theory or in <a href="/wiki/General_game_playing" title="General game playing">general game playing</a>.
</p><p>The game tree in Monte Carlo tree search grows asymmetrically as the method concentrates on the more promising subtrees. Thus it achieves better results than classical algorithms in games with a high <a href="/wiki/Branching_factor" title="Branching factor">branching factor</a>.
</p><p>Moreover, Monte Carlo tree search can be interrupted at <a href="/wiki/Anytime_algorithm" title="Anytime algorithm">any time</a> yielding the most promising move already found.
</p><p>A disadvantage is that, faced in a game with an expert player, there may be a single branch which leads to a loss. Because this is not easily found at random, the search may not "see" it and will not take it into account. It is believed that this may have been part of the reason for <a href="/wiki/AlphaGo_versus_Lee_Sedol" title="AlphaGo versus Lee Sedol">AlphaGo's loss in its fourth game against Lee Sedol</a>. In essence, the search attempts to prune sequences which are less relevant. In some cases, a play can lead to a very specific line of play which is significant, but which is overlooked when the tree is pruned, and this outcome is therefore "off the search radar".<sup id="cite_ref-39" class="reference"><a href="#cite_note-39">&#91;39&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Improvements">Improvements</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=6" title="Edit section: Improvements">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Various modifications of the basic Monte Carlo tree search method have been proposed to shorten the search time. Some employ domain-specific expert knowledge, others do not.
</p><p>Monte Carlo tree search can use either <i>light</i> or <i>heavy</i> playouts. Light playouts consist of random moves while heavy playouts apply various heuristics to influence the choice of moves.<sup id="cite_ref-40" class="reference"><a href="#cite_note-40">&#91;40&#93;</a></sup> These heuristics may employ the results of previous playouts (e.g. the Last Good Reply heuristic<sup id="cite_ref-41" class="reference"><a href="#cite_note-41">&#91;41&#93;</a></sup>) or expert knowledge of a given game. For instance, in many Go-playing programs certain stone patterns in a portion of the board influence the probability of moving into that area.<sup id="cite_ref-Gelly-et-al_17-1" class="reference"><a href="#cite_note-Gelly-et-al-17">&#91;17&#93;</a></sup> Paradoxically, playing suboptimally in simulations sometimes makes a Monte Carlo tree search program play stronger overall.<sup id="cite_ref-42" class="reference"><a href="#cite_note-42">&#91;42&#93;</a></sup>
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:655px;"><a href="/wiki/File:Mogo-hane.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/54/Mogo-hane.svg/653px-Mogo-hane.svg.png" decoding="async" width="653" height="128" class="thumbimage" data-file-width="653" data-file-height="128" /></a>  <div class="thumbcaption">Patterns of <i>hane</i> (surrounding opponent stones) used in playouts by the MoGo program. It is advantageous for both black and white to put a stone on the middle square, except the rightmost pattern where it favors black only.<sup id="cite_ref-Gelly-et-al_17-2" class="reference"><a href="#cite_note-Gelly-et-al-17">&#91;17&#93;</a></sup></div></div></div></div>
<p>Domain-specific knowledge may be employed when building the game tree to help the exploitation of some variants. One such method assigns nonzero <i>priors</i> to the number of won and played simulations when creating each child node, leading to artificially raised or lowered average win rates that cause the node to be chosen more or less frequently, respectively, in the selection step.<sup id="cite_ref-Gelly-Silver_43-0" class="reference"><a href="#cite_note-Gelly-Silver-43">&#91;43&#93;</a></sup> A related method, called <i>progressive bias</i>, consists in adding to the UCB1 formula a <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\frac {b_{i}}{n_{i}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <msub>
              <mi>b</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <msub>
              <mi>n</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\frac {b_{i}}{n_{i}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0b8d204678b182abcc9ca7a2a242d7c4f3e6bfe6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.171ex; width:3.031ex; height:5.676ex;" alt="{\displaystyle \frac{b_i}{n_i}}"/></span> element, where <span class="texhtml"><i>b</i><sub><i>i</i></sub></span> is a heuristic score of the  <span class="texhtml"><i>i</i></span>-th move.<sup id="cite_ref-chaslot2008_34-1" class="reference"><a href="#cite_note-chaslot2008-34">&#91;34&#93;</a></sup>
</p><p>The basic Monte Carlo tree search collects enough information to find the most promising moves only after many rounds; until then its moves are essentially random. This exploratory phase may be reduced significantly in a certain class of games using RAVE (<i>Rapid Action Value Estimation</i>).<sup id="cite_ref-Gelly-Silver_43-1" class="reference"><a href="#cite_note-Gelly-Silver-43">&#91;43&#93;</a></sup> In these games, permutations of a sequence of moves lead to the same position. Typically, they are board games in which a move involves placement of a piece or a stone on the board. In such games the value of each move is often only slightly influenced by other moves.
</p><p>In RAVE, for a given game tree node <span class="texhtml"><i>N</i></span>, its child nodes <span class="texhtml"><i>C</i><sub><i>i</i></sub></span> store not only the statistics of wins in playouts started in node <span class="texhtml"><i>N</i></span> but also the statistics of wins in all playouts started in node <span class="texhtml"><i>N</i></span> and below it, if they contain move <span class="texhtml"><i>i</i></span> (also when the move was played in the tree, between node <span class="texhtml"><i>N</i></span> and a playout). This way the contents of tree nodes are influenced not only by moves played immediately in a given position but also by the same moves played later.
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:443px;"><a href="/wiki/File:Tic-tac-toe-RAVE-English.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Tic-tac-toe-RAVE-English.svg/441px-Tic-tac-toe-RAVE-English.svg.png" decoding="async" width="441" height="427" class="thumbimage" data-file-width="441" data-file-height="427" /></a>  <div class="thumbcaption">RAVE on the example of tic-tac-toe. In red nodes, the RAVE statistics will be updated after the b1-a2-b3 simulation.</div></div></div></div>
<p>When using RAVE, the selection step selects the node, for which the modified UCB1 formula <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (1-\beta (n_{i},{\tilde {n}}_{i})){\frac {w_{i}}{n_{i}}}+\beta (n_{i},{\tilde {n}}_{i}){\frac {{\tilde {w}}_{i}}{{\tilde {n}}_{i}}}+c{\sqrt {\frac {\ln t}{n_{i}}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03B2;<!-- β --></mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>n</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>n</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <msub>
              <mi>w</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <msub>
              <mi>n</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mfrac>
        </mrow>
        <mo>+</mo>
        <mi>&#x03B2;<!-- β --></mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>n</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>n</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>w</mi>
                    <mo stretchy="false">&#x007E;<!-- ~ --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>n</mi>
                    <mo stretchy="false">&#x007E;<!-- ~ --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mfrac>
        </mrow>
        <mo>+</mo>
        <mi>c</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <msqrt>
            <mfrac>
              <mrow>
                <mi>ln</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mi>t</mi>
              </mrow>
              <msub>
                <mi>n</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
            </mfrac>
          </msqrt>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (1-\beta (n_{i},{\tilde {n}}_{i})){\frac {w_{i}}{n_{i}}}+\beta (n_{i},{\tilde {n}}_{i}){\frac {{\tilde {w}}_{i}}{{\tilde {n}}_{i}}}+c{\sqrt {\frac {\ln t}{n_{i}}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/efbb9b43358835c7c5aa81a7f8b9822a962bd807" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.171ex; width:42.554ex; height:7.676ex;" alt="{\displaystyle (1-\beta(n_i, \tilde{n}_i))\frac{w_i}{n_i} + \beta(n_i, \tilde{n}_i)\frac{\tilde{w}_i}{\tilde{n}_i} + c\sqrt{\frac{\ln t}{n_i}}}"/></span> has the highest value. In this formula, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\tilde {w}}_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>w</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\tilde {w}}_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/214ca375bfbaf1ac7c72eed96e70ba0a3d27a636" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.464ex; height:2.509ex;" alt="{\displaystyle \tilde{w}_i}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\tilde {n}}_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>n</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\tilde {n}}_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a6e600ae5c3e7149ac2d835b5d81baf1e92d184a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.194ex; height:2.509ex;" alt="{\displaystyle \tilde{n}_i}"/></span> stand for the number of won playouts containing move <span class="texhtml"><i>i</i></span> and the number of all playouts containing move <span class="texhtml"><i>i</i></span>, and the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \beta (n_{i},{\tilde {n}}_{i})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03B2;<!-- β --></mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>n</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>n</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \beta (n_{i},{\tilde {n}}_{i})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/62ecf97c8cf956c8a37e2eab5dca753168826fd2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.564ex; height:2.843ex;" alt="{\displaystyle \beta(n_i, \tilde{n}_i)}"/></span> function should be close to one and to zero for relatively small and relatively big <span class="texhtml"><i>n</i><sub><i>i</i></sub></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\tilde {n}}_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>n</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\tilde {n}}_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a6e600ae5c3e7149ac2d835b5d81baf1e92d184a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.194ex; height:2.509ex;" alt="{\displaystyle \tilde{n}_i}"/></span>, respectively. One of many formulas for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \beta (n_{i},{\tilde {n}}_{i})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03B2;<!-- β --></mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>n</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>n</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \beta (n_{i},{\tilde {n}}_{i})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/62ecf97c8cf956c8a37e2eab5dca753168826fd2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.564ex; height:2.843ex;" alt="{\displaystyle \beta(n_i, \tilde{n}_i)}"/></span>, proposed by D. Silver,<sup id="cite_ref-44" class="reference"><a href="#cite_note-44">&#91;44&#93;</a></sup> says that in balanced positions one can take <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \beta (n_{i},{\tilde {n}}_{i})={\frac {{\tilde {n}}_{i}}{n_{i}+{\tilde {n}}_{i}+4b^{2}n_{i}{\tilde {n}}_{i}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03B2;<!-- β --></mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>n</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>n</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mrow class="MJX-TeXAtom-ORD">
                  <mover>
                    <mi>n</mi>
                    <mo stretchy="false">&#x007E;<!-- ~ --></mo>
                  </mover>
                </mrow>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <mrow>
              <msub>
                <mi>n</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>n</mi>
                      <mo stretchy="false">&#x007E;<!-- ~ --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>+</mo>
              <mn>4</mn>
              <msup>
                <mi>b</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
              <msub>
                <mi>n</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>n</mi>
                      <mo stretchy="false">&#x007E;<!-- ~ --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \beta (n_{i},{\tilde {n}}_{i})={\frac {{\tilde {n}}_{i}}{n_{i}+{\tilde {n}}_{i}+4b^{2}n_{i}{\tilde {n}}_{i}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8d584bcb31eb6f6e051be555c83caf5baa4f4ad4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:30.171ex; height:5.843ex;" alt="{\displaystyle \beta(n_i, \tilde{n}_i)=\frac{\tilde{n}_i}{n_i+\tilde{n}_i+4b^2 n_i\tilde{n}_i}}"/></span>, where <span class="texhtml"><i>b</i></span> is an empirically chosen constant.
</p><p>Heuristics used in Monte Carlo tree search often require many parameters. There are automated methods to tune the parameters to maximize the win rate.<sup id="cite_ref-45" class="reference"><a href="#cite_note-45">&#91;45&#93;</a></sup>
</p><p>Monte Carlo tree search can be concurrently executed by many <a href="/wiki/Thread_(computing)" title="Thread (computing)">threads</a> or <a href="/wiki/Process_(computing)" title="Process (computing)">processes</a>. There are several fundamentally different methods of its <a href="/wiki/Parallel_computing" title="Parallel computing">parallel</a> execution:<sup id="cite_ref-46" class="reference"><a href="#cite_note-46">&#91;46&#93;</a></sup>
</p>
<ul><li><i>Leaf parallelization</i>, i.e. parallel execution of many playouts from one leaf of the game tree.</li>
<li><i>Root parallelization</i>, i.e. building independent game trees in parallel and making the move basing on the root-level branches of all these trees.</li>
<li><i>Tree parallelization</i>, i.e. parallel building of the same game tree, protecting data from simultaneous writes either with one, global <a href="/wiki/Mutex" class="mw-redirect" title="Mutex">mutex</a>, with more mutexes, or with <a href="/wiki/Non-blocking_algorithm" title="Non-blocking algorithm">non-blocking synchronization</a>.<sup id="cite_ref-47" class="reference"><a href="#cite_note-47">&#91;47&#93;</a></sup></li></ul>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=7" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/AlphaGo" title="AlphaGo">AlphaGo</a>, a Go program using Monte Carlo tree search, <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> and <a href="/wiki/Deep_learning" title="Deep learning">deep learning</a>.</li>
<li><a href="/wiki/AlphaGo_Zero" title="AlphaGo Zero">AlphaGo Zero</a>, an updated Go program using Monte Carlo tree search, <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> and <a href="/wiki/Deep_learning" title="Deep learning">deep learning</a>.</li>
<li><a href="/wiki/AlphaZero" title="AlphaZero">AlphaZero</a>, a generalized version of AlphaGo Zero using Monte Carlo tree search, <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> and <a href="/wiki/Deep_learning" title="Deep learning">deep learning</a>.</li>
<li><a href="/wiki/Leela_Chess_Zero" title="Leela Chess Zero">Leela Chess Zero</a>, a <a href="/wiki/Free_software" title="Free software">free software</a> implementation of AlphaZero's methods to chess, which is currently among the leading chess playing programs.</li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=8" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist columns references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-alphago-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-alphago_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-alphago_1-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal"><a href="/wiki/David_Silver_(programmer)" title="David Silver (programmer)">Silver, David</a>; <a href="/wiki/Aja_Huang" title="Aja Huang">Huang, Aja</a>; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda; Lanctot, Marc; Dieleman, Sander; Grewe, Dominik; Nham, John; Kalchbrenner, Nal; <a href="/wiki/Ilya_Sutskever" title="Ilya Sutskever">Sutskever, Ilya</a>; Lillicrap, Timothy; Leach, Madeleine; Kavukcuoglu, Koray; Graepel, Thore; <a href="/wiki/Demis_Hassabis" title="Demis Hassabis">Hassabis, Demis</a> (28 January 2016). "Mastering the game of Go with deep neural networks and tree search". <i><a href="/wiki/Nature_(journal)" title="Nature (journal)">Nature</a></i>. <b>529</b> (7587): 484–489. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="http://adsabs.harvard.edu/abs/2016Natur.529..484S">2016Natur.529..484S</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1038%2Fnature16961">10.1038/nature16961</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0028-0836">0028-0836</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/26819042">26819042</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature&amp;rft.atitle=Mastering+the+game+of+Go+with+deep+neural+networks+and+tree+search&amp;rft.volume=529&amp;rft.issue=7587&amp;rft.pages=484-489&amp;rft.date=2016-01-28&amp;rft_id=info%3Adoi%2F10.1038%2Fnature16961&amp;rft.issn=0028-0836&amp;rft_id=info%3Apmid%2F26819042&amp;rft_id=info%3Abibcode%2F2016Natur.529..484S&amp;rft.aulast=Silver&amp;rft.aufirst=David&amp;rft.au=Huang%2C+Aja&amp;rft.au=Maddison%2C+Chris+J.&amp;rft.au=Guez%2C+Arthur&amp;rft.au=Sifre%2C+Laurent&amp;rft.au=Driessche%2C+George+van+den&amp;rft.au=Schrittwieser%2C+Julian&amp;rft.au=Antonoglou%2C+Ioannis&amp;rft.au=Panneershelvam%2C+Veda&amp;rft.au=Lanctot%2C+Marc&amp;rft.au=Dieleman%2C+Sander&amp;rft.au=Grewe%2C+Dominik&amp;rft.au=Nham%2C+John&amp;rft.au=Kalchbrenner%2C+Nal&amp;rft.au=Sutskever%2C+Ilya&amp;rft.au=Lillicrap%2C+Timothy&amp;rft.au=Leach%2C+Madeleine&amp;rft.au=Kavukcuoglu%2C+Koray&amp;rft.au=Graepel%2C+Thore&amp;rft.au=Hassabis%2C+Demis&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r879151008">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style><span style="position:relative; top: -2px;"><a href="/wiki/Paywall" title="closed access publication – behind paywall"><img alt="closed access publication – behind paywall" src="//upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Closed_Access_logo_alternative.svg/9px-Closed_Access_logo_alternative.svg.png" decoding="async" width="9" height="14" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Closed_Access_logo_alternative.svg/14px-Closed_Access_logo_alternative.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Closed_Access_logo_alternative.svg/18px-Closed_Access_logo_alternative.svg.png 2x" data-file-width="640" data-file-height="1000" /></a></span></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Silver, David (2017). "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1712.01815v1">1712.01815v1</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Mastering+Chess+and+Shogi+by+Self-Play+with+a+General+Reinforcement+Learning+Algorithm&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1712.01815v1&amp;rft.aulast=Silver&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite class="citation book"><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Stuart J. Russell</a>, <a href="/wiki/Peter_Norvig" title="Peter Norvig">Peter Norvig</a> (2009). <a href="/wiki/Artificial_Intelligence:_A_Modern_Approach" title="Artificial Intelligence: A Modern Approach"><i>Artificial Intelligence: A Modern Approach</i></a> (3rd ed.). <a href="/wiki/Prentice_Hall" title="Prentice Hall">Prentice Hall</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+Modern+Approach&amp;rft.edition=3rd&amp;rft.pub=Prentice+Hall&amp;rft.date=2009&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: Uses authors parameter (<a href="/wiki/Category:CS1_maint:_Uses_authors_parameter" title="Category:CS1 maint: Uses authors parameter">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-cpr-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-cpr_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-cpr_4-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Jonathan Rubin; Ian Watson (April 2011). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20120813081731/https://www.cs.auckland.ac.nz/~jrub001/files/CPReviewPreprintAIJ.pdf">"Computer poker: A review"</a> <span class="cs1-format">(PDF)</span>. <i>Artificial Intelligence</i>. <b>175</b> (5–6): 958–987. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1016%2Fj.artint.2010.12.005">10.1016/j.artint.2010.12.005</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence&amp;rft.atitle=Computer+poker%3A+A+review&amp;rft.volume=175&amp;rft.issue=5%E2%80%936&amp;rft.pages=958-987&amp;rft.date=2011-04&amp;rft_id=info%3Adoi%2F10.1016%2Fj.artint.2010.12.005&amp;rft.au=Jonathan+Rubin&amp;rft.au=Ian+Watson&amp;rft_id=https%3A%2F%2Fweb.archive.org%2Fweb%2F20120813081731%2Fhttps%3A%2F%2Fwww.cs.auckland.ac.nz%2F~jrub001%2Ffiles%2FCPReviewPreprintAIJ.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://aigamedev.com/open/coverage/mcts-rome-ii/">"Monte-Carlo Tree Search in TOTAL WAR: ROME II's Campaign AI"</a>. <i>AI Game Dev</i><span class="reference-accessdate">. Retrieved <span class="nowrap">25 February</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=AI+Game+Dev&amp;rft.atitle=Monte-Carlo+Tree+Search+in+TOTAL+WAR%3A+ROME+II%27s+Campaign+AI&amp;rft_id=http%3A%2F%2Faigamedev.com%2Fopen%2Fcoverage%2Fmcts-rome-ii%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-Abramson-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-Abramson_6-0">^</a></b></span> <span class="reference-text"><cite class="citation book">Abramson, Bruce (1987). <a rel="nofollow" class="external text" href="http://academiccommons.columbia.edu/download/fedora_content/download/ac:142327/CONTENT/CUCS-315-87.pdf"><i>The Expected-Outcome Model of Two-Player Games</i></a> <span class="cs1-format">(PDF)</span>. Technical report, Department of Computer Science, Columbia University<span class="reference-accessdate">. Retrieved <span class="nowrap">23 December</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Expected-Outcome+Model+of+Two-Player+Games&amp;rft.pub=Technical+report%2C+Department+of+Computer+Science%2C+Columbia+University&amp;rft.date=1987&amp;rft.aulast=Abramson&amp;rft.aufirst=Bruce&amp;rft_id=http%3A%2F%2Facademiccommons.columbia.edu%2Fdownload%2Ffedora_content%2Fdownload%2Fac%3A142327%2FCONTENT%2FCUCS-315-87.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><cite class="citation book">Wolfgang Ertel; Johann Schumann; Christian Suttner (1989). <a rel="nofollow" class="external text" href="http://www.hs-weingarten.de/~ertel/veroeff_bib.html#ESS89">"Learning Heuristics for a Theorem Prover using Back Propagation."</a>.  In J. Retti; K. Leidlmair. <i>5. Österreichische Artificial-Intelligence-Tagung. Informatik-Fachberichte 208,pp. 87-95</i>. Springer.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Learning+Heuristics+for+a+Theorem+Prover+using+Back+Propagation.&amp;rft.btitle=5.+%C3%96sterreichische+Artificial-Intelligence-Tagung.+Informatik-Fachberichte+208%2Cpp.+87-95.&amp;rft.pub=Springer&amp;rft.date=1989&amp;rft.au=Wolfgang+Ertel&amp;rft.au=Johann+Schumann&amp;rft.au=Christian+Suttner&amp;rft_id=http%3A%2F%2Fwww.hs-weingarten.de%2F~ertel%2Fveroeff_bib.html%23ESS89&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation book">Christian Suttner; Wolfgang Ertel (1990). <a rel="nofollow" class="external text" href="http://www.hs-weingarten.de/~ertel/veroeff_bib.html#ES90:CADE">"Automatic Acquisition of Search Guiding Heuristics."</a>. <i>CADE90, 10th Int. Conf. on Automated Deduction.pp. 470-484. LNAI 449</i>. Springer.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Automatic+Acquisition+of+Search+Guiding+Heuristics.&amp;rft.btitle=CADE90%2C+10th+Int.+Conf.+on+Automated+Deduction.pp.+470-484.+LNAI+449.&amp;rft.pub=Springer&amp;rft.date=1990&amp;rft.au=Christian+Suttner&amp;rft.au=Wolfgang+Ertel&amp;rft_id=http%3A%2F%2Fwww.hs-weingarten.de%2F~ertel%2Fveroeff_bib.html%23ES90%3ACADE&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite class="citation journal">Christian Suttner; Wolfgang Ertel (1991). <a rel="nofollow" class="external text" href="http://www.hs-weingarten.de/~ertel/veroeff_bib.html#ES90:IJNN">"Using Back-Propagation Networks for Guiding the Search of a Theorem Prover"</a>. <i>Journal of Neural Networks Research &amp; Applications</i>. <b>2</b> (1): 3–16.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Neural+Networks+Research+%26+Applications&amp;rft.atitle=Using+Back-Propagation+Networks+for+Guiding+the+Search+of+a+Theorem+Prover.&amp;rft.volume=2&amp;rft.issue=1&amp;rft.pages=3-16&amp;rft.date=1991&amp;rft.au=Christian+Suttner&amp;rft.au=Wolfgang+Ertel&amp;rft_id=http%3A%2F%2Fwww.hs-weingarten.de%2F~ertel%2Fveroeff_bib.html%23ES90%3AIJNN&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-Bruegmann-10"><span class="mw-cite-backlink">^ <a href="#cite_ref-Bruegmann_10-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Bruegmann_10-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation book">Brügmann, Bernd (1993). <a rel="nofollow" class="external text" href="http://www.ideanest.com/vegos/MonteCarloGo.pdf"><i>Monte Carlo Go</i></a> <span class="cs1-format">(PDF)</span>. Technical report, Department of Physics, Syracuse University.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Monte+Carlo+Go&amp;rft.pub=Technical+report%2C+Department+of+Physics%2C+Syracuse+University&amp;rft.date=1993&amp;rft.aulast=Br%C3%BCgmann&amp;rft.aufirst=Bernd&amp;rft_id=http%3A%2F%2Fwww.ideanest.com%2Fvegos%2FMonteCarloGo.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-Chang2005-11"><span class="mw-cite-backlink">^ <a href="#cite_ref-Chang2005_11-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Chang2005_11-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Chang2005_11-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Chang, Hyeong Soo; Fu, Michael C.; Hu, Jiaqiao; Marcus, Steven I. (2005). <a rel="nofollow" class="external text" href="http://scholar.rhsmith.umd.edu/sites/default/files/mfu/files/cfhm05.pdf?m=1449834091">"An Adaptive Sampling Algorithm for Solving Markov Decision Processes"</a> <span class="cs1-format">(PDF)</span>. <i>Operations Research</i>. <b>53</b>: 126–139. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1287%2Fopre.1040.0145">10.1287/opre.1040.0145</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Operations+Research&amp;rft.atitle=An+Adaptive+Sampling+Algorithm+for+Solving+Markov+Decision+Processes&amp;rft.volume=53&amp;rft.pages=126-139&amp;rft.date=2005&amp;rft_id=info%3Adoi%2F10.1287%2Fopre.1040.0145&amp;rft.aulast=Chang&amp;rft.aufirst=Hyeong+Soo&amp;rft.au=Fu%2C+Michael+C.&amp;rft.au=Hu%2C+Jiaqiao&amp;rft.au=Marcus%2C+Steven+I.&amp;rft_id=http%3A%2F%2Fscholar.rhsmith.umd.edu%2Fsites%2Fdefault%2Ffiles%2Fmfu%2Ffiles%2Fcfhm05.pdf%3Fm%3D1449834091&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-changORMStoday-12"><span class="mw-cite-backlink">^ <a href="#cite_ref-changORMStoday_12-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-changORMStoday_12-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Hyeong Soo Chang; Michael Fu; Jiaqiao Hu; Steven I. Marcus (2016). <a rel="nofollow" class="external text" href="https://www.informs.org/ORMS-Today/Public-Articles/October-Volume-43-Number-5">"Google DeepMind's Alphago: O.R.'s unheralded role in the path-breaking achievement"</a>. <i>ORMS Today</i>. <b>45</b> (5): 24–29.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ORMS+Today&amp;rft.atitle=Google+DeepMind%27s+Alphago%3A+O.R.%27s+unheralded+role+in+the+path-breaking+achievement&amp;rft.volume=45&amp;rft.issue=5&amp;rft.pages=24-29&amp;rft.date=2016&amp;rft.au=Hyeong+Soo+Chang&amp;rft.au=Michael+Fu&amp;rft.au=Jiaqiao+Hu&amp;rft.au=Steven+I.+Marcus&amp;rft_id=https%3A%2F%2Fwww.informs.org%2FORMS-Today%2FPublic-Articles%2FOctober-Volume-43-Number-5&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://senseis.xmp.net/?KGSBotRatings">"Sensei's Library: KGSBotRatings"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2012-05-03</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Sensei%27s+Library%3A+KGSBotRatings&amp;rft_id=http%3A%2F%2Fsenseis.xmp.net%2F%3FKGSBotRatings&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation book"><a href="/wiki/R%C3%A9mi_Coulom" title="Rémi Coulom">Rémi Coulom</a> (2008). <a rel="nofollow" class="external text" href="http://remi.coulom.free.fr/JFFoS/JFFoS.pdf">"The Monte-Carlo Revolution in Go"</a> <span class="cs1-format">(PDF)</span>. <i>Japanese-French Frontiers of Science Symposium</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=The+Monte-Carlo+Revolution+in+Go&amp;rft.btitle=Japanese-French+Frontiers+of+Science+Symposium&amp;rft.date=2008&amp;rft.au=R%C3%A9mi+Coulom&amp;rft_id=http%3A%2F%2Fremi.coulom.free.fr%2FJFFoS%2FJFFoS.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><cite class="citation book"><a href="/wiki/R%C3%A9mi_Coulom" title="Rémi Coulom">Rémi Coulom</a> (2007). "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search". <i>Computers and Games, 5th International Conference, CG 2006, Turin, Italy, May 29–31, 2006. Revised Papers</i>. H. Jaap van den Herik, Paolo Ciancarini, H. H. L. M. Donkers (eds.). Springer. pp.&#160;72–83. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.81.6817">10.1.1.81.6817</a></span>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-75537-1" title="Special:BookSources/978-3-540-75537-1">978-3-540-75537-1</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Efficient+Selectivity+and+Backup+Operators+in+Monte-Carlo+Tree+Search&amp;rft.btitle=Computers+and+Games%2C+5th+International+Conference%2C+CG+2006%2C+Turin%2C+Italy%2C+May+29%E2%80%9331%2C+2006.+Revised+Papers&amp;rft.pages=72-83&amp;rft.pub=Springer&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.81.6817&amp;rft.isbn=978-3-540-75537-1&amp;rft.au=R%C3%A9mi+Coulom&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-Kocsis-Szepesvari-16"><span class="mw-cite-backlink">^ <a href="#cite_ref-Kocsis-Szepesvari_16-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Kocsis-Szepesvari_16-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation conference">Kocsis, Levente; Szepesvári, Csaba (2006). "Bandit based Monte-Carlo Planning".  In Fürnkranz, Johannes; Scheffer, Tobias; Spiliopoulou, Myra. <i>Machine Learning: ECML 2006, 17th European Conference on Machine Learning, Berlin, Germany, September 18–22, 2006, Proceedings</i>. Lecture Notes in Computer Science. <b>4212</b>. Springer. pp.&#160;282–293. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.102.1296">10.1.1.102.1296</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1007%2F11871842_29">10.1007/11871842_29</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/3-540-45375-X" title="Special:BookSources/3-540-45375-X">3-540-45375-X</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Bandit+based+Monte-Carlo+Planning&amp;rft.btitle=Machine+Learning%3A+ECML+2006%2C+17th+European+Conference+on+Machine+Learning%2C+Berlin%2C+Germany%2C+September+18%E2%80%9322%2C+2006%2C+Proceedings&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=282-293&amp;rft.pub=Springer&amp;rft.date=2006&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.102.1296&amp;rft_id=info%3Adoi%2F10.1007%2F11871842_29&amp;rft.isbn=3-540-45375-X&amp;rft.aulast=Kocsis&amp;rft.aufirst=Levente&amp;rft.au=Szepesv%C3%A1ri%2C+Csaba&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-Gelly-et-al-17"><span class="mw-cite-backlink">^ <a href="#cite_ref-Gelly-et-al_17-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Gelly-et-al_17-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Gelly-et-al_17-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation book">Sylvain Gelly; Yizao Wang; Rémi Munos; Olivier Teytaud (November 2006). <a rel="nofollow" class="external text" href="http://hal.inria.fr/docs/00/11/72/66/PDF/MoGoReport.pdf"><i>Modification of UCT with Patterns in Monte-Carlo Go</i></a> <span class="cs1-format">(PDF)</span>. Technical report, INRIA.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Modification+of+UCT+with+Patterns+in+Monte-Carlo+Go&amp;rft.pub=Technical+report%2C+INRIA&amp;rft.date=2006-11&amp;rft.au=Sylvain+Gelly&amp;rft.au=Yizao+Wang&amp;rft.au=R%C3%A9mi+Munos&amp;rft.au=Olivier+Teytaud&amp;rft_id=http%3A%2F%2Fhal.inria.fr%2Fdocs%2F00%2F11%2F72%2F66%2FPDF%2FMoGoReport.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal">Chang-Shing Lee; Mei-Hui Wang; Guillaume Chaslot; Jean-Baptiste Hoock; Arpad Rimmel; Olivier Teytaud; Shang-Rong Tsai; Shun-Chin Hsu; Tzung-Pei Hong (2009). <a rel="nofollow" class="external text" href="http://hal.inria.fr/docs/00/36/97/86/PDF/TCIAIG-2008-0010_Accepted_.pdf">"The Computational Intelligence of MoGo Revealed in Taiwan's Computer Go Tournaments"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Transactions on Computational Intelligence and AI in Games</i>. <b>1</b> (1): 73–89. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.470.6018">10.1.1.470.6018</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1109%2Ftciaig.2009.2018703">10.1109/tciaig.2009.2018703</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Computational+Intelligence+and+AI+in+Games&amp;rft.atitle=The+Computational+Intelligence+of+MoGo+Revealed+in+Taiwan%27s+Computer+Go+Tournaments&amp;rft.volume=1&amp;rft.issue=1&amp;rft.pages=73-89&amp;rft.date=2009&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.470.6018&amp;rft_id=info%3Adoi%2F10.1109%2Ftciaig.2009.2018703&amp;rft.au=Chang-Shing+Lee&amp;rft.au=Mei-Hui+Wang&amp;rft.au=Guillaume+Chaslot&amp;rft.au=Jean-Baptiste+Hoock&amp;rft.au=Arpad+Rimmel&amp;rft.au=Olivier+Teytaud&amp;rft.au=Shang-Rong+Tsai&amp;rft.au=Shun-Chin+Hsu&amp;rft.au=Tzung-Pei+Hong&amp;rft_id=http%3A%2F%2Fhal.inria.fr%2Fdocs%2F00%2F36%2F97%2F86%2FPDF%2FTCIAIG-2008-0010_Accepted_.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><cite class="citation book">Markus Enzenberger; Martin Mūller (2008). <a rel="nofollow" class="external text" href="http://pug.raph.free.fr/files/Fuego.pdf"><i>Fuego – An Open-Source Framework for Board Games and Go Engine Based on Monte Carlo Tree Search</i></a> <span class="cs1-format">(PDF)</span>. Technical report, University of Alberta.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Fuego+%E2%80%93+An+Open-Source+Framework+for+Board+Games+and+Go+Engine+Based+on+Monte+Carlo+Tree+Search&amp;rft.pub=Technical+report%2C+University+of+Alberta&amp;rft.date=2008&amp;rft.au=Markus+Enzenberger&amp;rft.au=Martin+M%C5%ABller&amp;rft_id=http%3A%2F%2Fpug.raph.free.fr%2Ffiles%2FFuego.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://dcook.org/gobet/">"The Shodan Go Bet"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2012-05-02</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Shodan+Go+Bet&amp;rft_id=http%3A%2F%2Fdcook.org%2Fgobet%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://googleresearch.blogspot.com/2016/01/alphago-mastering-ancient-game-of-go.html">"Research Blog: AlphaGo: Mastering the ancient game of Go with Machine Learning"</a>. <i>Google Research Blog</i>. 27 January 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google+Research+Blog&amp;rft.atitle=Research+Blog%3A+AlphaGo%3A+Mastering+the+ancient+game+of+Go+with+Machine+Learning&amp;rft.date=2016-01-27&amp;rft_id=http%3A%2F%2Fgoogleresearch.blogspot.com%2F2016%2F01%2Falphago-mastering-ancient-game-of-go.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.bbc.com/news/technology-35420579">"Google achieves AI 'breakthrough' by beating Go champion"</a>. <i>BBC News</i>. 27 January 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=BBC+News&amp;rft.atitle=Google+achieves+AI+%27breakthrough%27+by+beating+Go+champion&amp;rft.date=2016-01-27&amp;rft_id=https%3A%2F%2Fwww.bbc.com%2Fnews%2Ftechnology-35420579&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=vFr3K2DORc8&amp;t=1h57m">"Match 1 - Google DeepMind Challenge Match: Lee Sedol vs AlphaGo"</a>. <i>Youtube</i>. 9 March 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Youtube&amp;rft.atitle=Match+1+-+Google+DeepMind+Challenge+Match%3A+Lee+Sedol+vs+AlphaGo&amp;rft.date=2016-03-09&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DvFr3K2DORc8%26t%3D1h57m&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.zdnet.com/article/google-alphago-ai-clean-sweeps-european-go-champion/">"Google AlphaGo AI clean sweeps European Go champion"</a>. <i>ZDNet</i>. 28 January 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ZDNet&amp;rft.atitle=Google+AlphaGo+AI+clean+sweeps+European+Go+champion&amp;rft.date=2016-01-28&amp;rft_id=http%3A%2F%2Fwww.zdnet.com%2Farticle%2Fgoogle-alphago-ai-clean-sweeps-european-go-champion%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation journal">Broderick Arneson; Ryan Hayward; Philip Henderson (June 2009). <a rel="nofollow" class="external text" href="http://webdocs.cs.ualberta.ca/~hayward/papers/rptPamplona.pdf">"MoHex Wins Hex Tournament"</a> <span class="cs1-format">(PDF)</span>. <i>ICGA Journal</i>. <b>32</b> (2): 114–116. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.3233%2FICG-2009-32218">10.3233/ICG-2009-32218</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ICGA+Journal&amp;rft.atitle=MoHex+Wins+Hex+Tournament&amp;rft.volume=32&amp;rft.issue=2&amp;rft.pages=114-116&amp;rft.date=2009-06&amp;rft_id=info%3Adoi%2F10.3233%2FICG-2009-32218&amp;rft.au=Broderick+Arneson&amp;rft.au=Ryan+Hayward&amp;rft.au=Philip+Henderson&amp;rft_id=http%3A%2F%2Fwebdocs.cs.ualberta.ca%2F~hayward%2Fpapers%2FrptPamplona.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation book">Timo Ewalds (2011). <a rel="nofollow" class="external text" href="http://havannah.ewalds.ca/static/thesis.pdf"><i>Playing and Solving Havannah</i></a> <span class="cs1-format">(PDF)</span>. Master's thesis, University of Alberta.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Playing+and+Solving+Havannah&amp;rft.pub=Master%27s+thesis%2C+University+of+Alberta&amp;rft.date=2011&amp;rft.au=Timo+Ewalds&amp;rft_id=http%3A%2F%2Fhavannah.ewalds.ca%2Fstatic%2Fthesis.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation book">Richard J. Lorentz (2008). "Amazons Discover Monte-Carlo". <i>Computers and Games, 6th International Conference, CG 2008, Beijing, China, September 29 – October 1, 2008. Proceedings</i>. H. Jaap van den Herik, Xinhe Xu, Zongmin Ma, Mark H. M. Winands (eds.). Springer. pp.&#160;13–24. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-87607-6" title="Special:BookSources/978-3-540-87607-6">978-3-540-87607-6</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Amazons+Discover+Monte-Carlo&amp;rft.btitle=Computers+and+Games%2C+6th+International+Conference%2C+CG+2008%2C+Beijing%2C+China%2C+September+29+%E2%80%93+October+1%2C+2008.+Proceedings&amp;rft.pages=13-24&amp;rft.pub=Springer&amp;rft.date=2008&amp;rft.isbn=978-3-540-87607-6&amp;rft.au=Richard+J.+Lorentz&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><cite class="citation book">Tomáš Kozelek (2009). <a rel="nofollow" class="external text" href="http://arimaa.com/arimaa/papers/TomasKozelekThesis/mt.pdf"><i>Methods of MCTS and the game Arimaa</i></a> <span class="cs1-format">(PDF)</span>. Master's thesis, Charles University in Prague.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Methods+of+MCTS+and+the+game+Arimaa&amp;rft.pub=Master%27s+thesis%2C+Charles+University+in+Prague&amp;rft.date=2009&amp;rft.au=Tom%C3%A1%C5%A1+Kozelek&amp;rft_id=http%3A%2F%2Farimaa.com%2Farimaa%2Fpapers%2FTomasKozelekThesis%2Fmt.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><cite class="citation journal">Xiaocong Gan; Yun Bao; Zhangang Han (December 2011). "Real-Time Search Method in Nondeterministic Game – Ms. Pac-Man". <i>ICGA Journal</i>. <b>34</b> (4): 209–222. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.3233%2FICG-2011-34404">10.3233/ICG-2011-34404</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ICGA+Journal&amp;rft.atitle=Real-Time+Search+Method+in+Nondeterministic+Game+%E2%80%93+Ms.+Pac-Man&amp;rft.volume=34&amp;rft.issue=4&amp;rft.pages=209-222&amp;rft.date=2011-12&amp;rft_id=info%3Adoi%2F10.3233%2FICG-2011-34404&amp;rft.au=Xiaocong+Gan&amp;rft.au=Yun+Bao&amp;rft.au=Zhangang+Han&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><cite class="citation journal">Tom Pepels; Mark H. M. Winands; Marc Lanctot (September 2014). "Real-Time Monte Carlo Tree Search in Ms Pac-Man". <i>IEEE Transactions on Computational Intelligence and AI in Games</i>. <b>6</b> (3): 245–257. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1109%2Ftciaig.2013.2291577">10.1109/tciaig.2013.2291577</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Computational+Intelligence+and+AI+in+Games&amp;rft.atitle=Real-Time+Monte+Carlo+Tree+Search+in+Ms+Pac-Man&amp;rft.volume=6&amp;rft.issue=3&amp;rft.pages=245-257&amp;rft.date=2014-09&amp;rft_id=info%3Adoi%2F10.1109%2Ftciaig.2013.2291577&amp;rft.au=Tom+Pepels&amp;rft.au=Mark+H.+M.+Winands&amp;rft.au=Marc+Lanctot&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><cite class="citation book">Michael Buro; Jeffrey Richard Long; Timothy Furtak; Nathan R. Sturtevant (2009). "Improving State Evaluation, Inference, and Search in Trick-Based Card Games". <i>IJCAI 2009, Proceedings of the 21st International Joint Conference on Artificial Intelligence, Pasadena, California, USA, July 11–17, 2009</i>. Craig Boutilier (ed.). pp.&#160;1407–1413. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.150.3077">10.1.1.150.3077</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Improving+State+Evaluation%2C+Inference%2C+and+Search+in+Trick-Based+Card+Games&amp;rft.btitle=IJCAI+2009%2C+Proceedings+of+the+21st+International+Joint+Conference+on+Artificial+Intelligence%2C+Pasadena%2C+California%2C+USA%2C+July+11%E2%80%9317%2C+2009&amp;rft.pages=1407-1413&amp;rft.date=2009&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.150.3077&amp;rft.au=Michael+Buro&amp;rft.au=Jeffrey+Richard+Long&amp;rft.au=Timothy+Furtak&amp;rft.au=Nathan+R.+Sturtevant&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text"><cite class="citation book">C.D. Ward; P.I. Cowling (2009). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20160528074031/http://scim.brad.ac.uk/staff/pdf/picowlin/CIG2009.pdf">"Monte Carlo Search Applied to Card Selection in Magic: The Gathering"</a> <span class="cs1-format">(PDF)</span>. <i>CIG'09 Proceedings of the 5th international conference on Computational Intelligence and Games</i>. IEEE Press. Archived from <a rel="nofollow" class="external text" href="http://scim.brad.ac.uk/staff/pdf/picowlin/CIG2009.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2016-05-28.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Monte+Carlo+Search+Applied+to+Card+Selection+in+Magic%3A+The+Gathering&amp;rft.btitle=CIG%2709+Proceedings+of+the+5th+international+conference+on+Computational+Intelligence+and+Games&amp;rft.pub=IEEE+Press&amp;rft.date=2009&amp;rft.au=C.D.+Ward&amp;rft.au=P.I.+Cowling&amp;rft_id=http%3A%2F%2Fscim.brad.ac.uk%2Fstaff%2Fpdf%2Fpicowlin%2FCIG2009.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><cite class="citation book">István Szita; Guillaume Chaslot; Pieter Spronck (2010). <a rel="nofollow" class="external text" href="http://ticc.uvt.nl/icga/acg12/proceedings/Contribution100.pdf">"Monte-Carlo Tree Search in Settlers of Catan"</a> <span class="cs1-format">(PDF)</span>.  In Jaap Van Den Herik; Pieter Spronck. <i>Advances in Computer Games, 12th International Conference, ACG 2009, Pamplona, Spain, May 11–13, 2009. Revised Papers</i>. Springer. pp.&#160;21–32. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-642-12992-6" title="Special:BookSources/978-3-642-12992-6">978-3-642-12992-6</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Monte-Carlo+Tree+Search+in+Settlers+of+Catan&amp;rft.btitle=Advances+in+Computer+Games%2C+12th+International+Conference%2C+ACG+2009%2C+Pamplona%2C+Spain%2C+May+11%E2%80%9313%2C+2009.+Revised+Papers&amp;rft.pages=21-32&amp;rft.pub=Springer&amp;rft.date=2010&amp;rft.isbn=978-3-642-12992-6&amp;rft.au=Istv%C3%A1n+Szita&amp;rft.au=Guillaume+Chaslot&amp;rft.au=Pieter+Spronck&amp;rft_id=http%3A%2F%2Fticc.uvt.nl%2Ficga%2Facg12%2Fproceedings%2FContribution100.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-chaslot2008-34"><span class="mw-cite-backlink">^ <a href="#cite_ref-chaslot2008_34-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-chaslot2008_34-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">G.M.J.B. Chaslot; M.H.M. Winands; J.W.H.M. Uiterwijk; H.J. van den Herik; B. Bouzy (2008). <a rel="nofollow" class="external text" href="https://dke.maastrichtuniversity.nl/m.winands/documents/pMCTS.pdf">"Progressive Strategies for Monte-Carlo Tree Search"</a> <span class="cs1-format">(PDF)</span>. <i>New Mathematics and Natural Computation</i>. <b>4</b> (3): 343–359. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1142%2Fs1793005708001094">10.1142/s1793005708001094</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=New+Mathematics+and+Natural+Computation&amp;rft.atitle=Progressive+Strategies+for+Monte-Carlo+Tree+Search&amp;rft.volume=4&amp;rft.issue=3&amp;rft.pages=343-359&amp;rft.date=2008&amp;rft_id=info%3Adoi%2F10.1142%2Fs1793005708001094&amp;rft.au=G.M.J.B.+Chaslot&amp;rft.au=M.H.M.+Winands&amp;rft.au=J.W.H.M.+Uiterwijk&amp;rft.au=H.J.+van+den+Herik&amp;rft.au=B.+Bouzy&amp;rft_id=https%3A%2F%2Fdke.maastrichtuniversity.nl%2Fm.winands%2Fdocuments%2FpMCTS.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><cite class="citation web">Bradberry, Jeff (2015-09-07). <a rel="nofollow" class="external text" href="http://jeffbradberry.com/posts/2015/09/intro-to-monte-carlo-tree-search/">"Introduction to Monte Carlo Tree Search"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Introduction+to+Monte+Carlo+Tree+Search&amp;rft.date=2015-09-07&amp;rft.aulast=Bradberry&amp;rft.aufirst=Jeff&amp;rft_id=http%3A%2F%2Fjeffbradberry.com%2Fposts%2F2015%2F09%2Fintro-to-monte-carlo-tree-search%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Peres, Yuval; Schramm, Oded; Sheffield, Scott; Wilson, David B. (2006). "Random-Turn Hex and other selection games". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/math/0508580">math/0508580</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Random-Turn+Hex+and+other+selection+games&amp;rft.date=2006&amp;rft_id=info%3Aarxiv%2Fmath%2F0508580&amp;rft.aulast=Peres&amp;rft.aufirst=Yuval&amp;rft.au=Schramm%2C+Oded&amp;rft.au=Sheffield%2C+Scott&amp;rft.au=Wilson%2C+David+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text"><cite class="citation journal">Auer, Peter; Cesa-Bianchi, Nicolò; Fischer, Paul (2002). <a rel="nofollow" class="external text" href="http://moodle.technion.ac.il/pluginfile.php/192340/mod_resource/content/0/UCB.pdf">"Finite-time Analysis of the Multiarmed Bandit Problem"</a> <span class="cs1-format">(PDF)</span>. <i>Machine Learning</i>. <b>47</b> (2/3): 235–256. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1023%2Fa%3A1013689704352">10.1023/a:1013689704352</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Finite-time+Analysis+of+the+Multiarmed+Bandit+Problem&amp;rft.volume=47&amp;rft.issue=2%2F3&amp;rft.pages=235-256&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1023%2Fa%3A1013689704352&amp;rft.aulast=Auer&amp;rft.aufirst=Peter&amp;rft.au=Cesa-Bianchi%2C+Nicol%C3%B2&amp;rft.au=Fischer%2C+Paul&amp;rft_id=http%3A%2F%2Fmoodle.technion.ac.il%2Fpluginfile.php%2F192340%2Fmod_resource%2Fcontent%2F0%2FUCB.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/><sup class="noprint Inline-Template"><span style="white-space: nowrap;">&#91;<i><a href="/wiki/Wikipedia:Link_rot" title="Wikipedia:Link rot"><span title="&#160;Dead link since February 2018">permanent dead link</span></a></i>&#93;</span></sup></span>
</li>
<li id="cite_note-38"><span class="mw-cite-backlink"><b><a href="#cite_ref-38">^</a></b></span> <span class="reference-text"><cite class="citation book">Bouzy, Bruno. <a rel="nofollow" class="external text" href="http://ewh.ieee.org/cmte/cis/mtsc/ieeecis/tutorial2007/Bruno_Bouzy_2007.pdf">"Old-fashioned Computer Go vs Monte-Carlo Go"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Symposium on Computational Intelligence and Games, April 1–5, 2007, Hilton Hawaiian Village, Honolulu, Hawaii</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Old-fashioned+Computer+Go+vs+Monte-Carlo+Go&amp;rft.btitle=IEEE+Symposium+on+Computational+Intelligence+and+Games%2C+April+1%E2%80%935%2C+2007%2C+Hilton+Hawaiian+Village%2C+Honolulu%2C+Hawaii&amp;rft.aulast=Bouzy&amp;rft.aufirst=Bruno&amp;rft_id=http%3A%2F%2Fewh.ieee.org%2Fcmte%2Fcis%2Fmtsc%2Fieeecis%2Ftutorial2007%2FBruno_Bouzy_2007.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-39">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://gogameguru.com/lee-sedol-defeats-alphago-masterful-comeback-game-4/">"Lee Sedol defeats AlphaGo in masterful comeback - Game 4"</a>. Go Game Guru.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lee+Sedol+defeats+AlphaGo+in+masterful+comeback+-+Game+4&amp;rft.pub=Go+Game+Guru&amp;rft_id=https%3A%2F%2Fgogameguru.com%2Flee-sedol-defeats-alphago-masterful-comeback-game-4%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-40">^</a></b></span> <span class="reference-text">Swiechowski, M.; Mandziuk, J., "Self-Adaptation of Playing Strategies in General Game Playing" (2010), <i>IEEE Transactions on Computational Intelligence and AI in Games</i>, doi: 10.1109/TCIAIG.2013.2275163, <a rel="nofollow" class="external free" href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6571225&amp;isnumber=4804729">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6571225&amp;isnumber=4804729</a></span>
</li>
<li id="cite_note-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-41">^</a></b></span> <span class="reference-text"><cite class="citation journal">Drake, Peter (December 2009). "The Last-Good-Reply Policy for Monte-Carlo Go". <i>ICGA Journal</i>. <b>32</b> (4): 221–227. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.3233%2FICG-2009-32404">10.3233/ICG-2009-32404</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ICGA+Journal&amp;rft.atitle=The+Last-Good-Reply+Policy+for+Monte-Carlo+Go&amp;rft.volume=32&amp;rft.issue=4&amp;rft.pages=221-227&amp;rft.date=2009-12&amp;rft_id=info%3Adoi%2F10.3233%2FICG-2009-32404&amp;rft.aulast=Drake&amp;rft.aufirst=Peter&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-42">^</a></b></span> <span class="reference-text"><cite class="citation book">Seth Pellegrino; Peter Drake (2010). "Investigating the Effects of Playout Strength in Monte-Carlo Go". <i>Proceedings of the 2010 International Conference on Artificial Intelligence, ICAI 2010, July 12–15, 2010, Las Vegas Nevada, USA</i>. Hamid R. Arabnia, David de la Fuente, Elena B. Kozerenko, José Angel Olivas, Rui Chang, Peter M. LaMonica, Raymond A. Liuzzi, Ashu M. G. Solo (eds.). CSREA Press. pp.&#160;1015–1018. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-60132-148-0" title="Special:BookSources/978-1-60132-148-0">978-1-60132-148-0</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Investigating+the+Effects+of+Playout+Strength+in+Monte-Carlo+Go&amp;rft.btitle=Proceedings+of+the+2010+International+Conference+on+Artificial+Intelligence%2C+ICAI+2010%2C+July+12%E2%80%9315%2C+2010%2C+Las+Vegas+Nevada%2C+USA&amp;rft.pages=1015-1018&amp;rft.pub=CSREA+Press&amp;rft.date=2010&amp;rft.isbn=978-1-60132-148-0&amp;rft.au=Seth+Pellegrino&amp;rft.au=Peter+Drake&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-Gelly-Silver-43"><span class="mw-cite-backlink">^ <a href="#cite_ref-Gelly-Silver_43-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Gelly-Silver_43-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation book">Sylvain Gelly; David Silver (2007). <a rel="nofollow" class="external text" href="http://www.machinelearning.org/proceedings/icml2007/papers/387.pdf">"Combining Online and Offline Knowledge in UCT"</a> <span class="cs1-format">(PDF)</span>. <i>Machine Learning, Proceedings of the Twenty-Fourth International Conference (ICML 2007), Corvallis, Oregon, USA, June 20–24, 2007</i>. Zoubin Ghahramani (ed.). ACM. pp.&#160;273–280. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-59593-793-3" title="Special:BookSources/978-1-59593-793-3">978-1-59593-793-3</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Combining+Online+and+Offline+Knowledge+in+UCT&amp;rft.btitle=Machine+Learning%2C+Proceedings+of+the+Twenty-Fourth+International+Conference+%28ICML+2007%29%2C+Corvallis%2C+Oregon%2C+USA%2C+June+20%E2%80%9324%2C+2007&amp;rft.pages=273-280&amp;rft.pub=ACM&amp;rft.date=2007&amp;rft.isbn=978-1-59593-793-3&amp;rft.au=Sylvain+Gelly&amp;rft.au=David+Silver&amp;rft_id=http%3A%2F%2Fwww.machinelearning.org%2Fproceedings%2Ficml2007%2Fpapers%2F387.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-44">^</a></b></span> <span class="reference-text"><cite class="citation book">David Silver (2009). <a rel="nofollow" class="external text" href="http://papersdb.cs.ualberta.ca/~papersdb/uploaded_files/1029/paper_thesis.pdf"><i>Reinforcement Learning and Simulation-Based Search in Computer Go</i></a> <span class="cs1-format">(PDF)</span>. PhD thesis, University of Alberta.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Reinforcement+Learning+and+Simulation-Based+Search+in+Computer+Go&amp;rft.pub=PhD+thesis%2C+University+of+Alberta&amp;rft.date=2009&amp;rft.au=David+Silver&amp;rft_id=http%3A%2F%2Fpapersdb.cs.ualberta.ca%2F~papersdb%2Fuploaded_files%2F1029%2Fpaper_thesis.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-45">^</a></b></span> <span class="reference-text"><cite class="citation book"><a href="/wiki/R%C3%A9mi_Coulom" title="Rémi Coulom">Rémi Coulom</a>. <a rel="nofollow" class="external text" href="http://remi.coulom.free.fr/CLOP/">"CLOP: Confident Local Optimization for Noisy Black-Box Parameter Tuning"</a>. <i>ACG 2011: Advances in Computer Games 13 Conference, Tilburg, the Netherlands, November 20–22</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=CLOP%3A+Confident+Local+Optimization+for+Noisy+Black-Box+Parameter+Tuning&amp;rft.btitle=ACG+2011%3A+Advances+in+Computer+Games+13+Conference%2C+Tilburg%2C+the+Netherlands%2C+November+20%E2%80%9322&amp;rft.au=R%C3%A9mi+Coulom&amp;rft_id=http%3A%2F%2Fremi.coulom.free.fr%2FCLOP%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-46">^</a></b></span> <span class="reference-text"><cite class="citation book">Guillaume M.J-B. Chaslot, Mark H.M. Winands, <a href="/wiki/Jaap_van_den_Herik" title="Jaap van den Herik">Jaap van den Herik</a> (2008). <a rel="nofollow" class="external text" href="https://dke.maastrichtuniversity.nl/m.winands/documents/multithreadedMCTS2.pdf">"Parallel Monte-Carlo Tree Search"</a> <span class="cs1-format">(PDF)</span>. <i>Computers and Games, 6th International Conference, CG 2008, Beijing, China, September 29 – October 1, 2008. Proceedings</i>. H. Jaap van den Herik, Xinhe Xu, Zongmin Ma, Mark H. M. Winands (eds.). Springer. pp.&#160;60–71. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-87607-6" title="Special:BookSources/978-3-540-87607-6">978-3-540-87607-6</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Parallel+Monte-Carlo+Tree+Search&amp;rft.btitle=Computers+and+Games%2C+6th+International+Conference%2C+CG+2008%2C+Beijing%2C+China%2C+September+29+%E2%80%93+October+1%2C+2008.+Proceedings&amp;rft.pages=60-71&amp;rft.pub=Springer&amp;rft.date=2008&amp;rft.isbn=978-3-540-87607-6&amp;rft.au=Guillaume+M.J-B.+Chaslot%2C+Mark+H.M.+Winands%2C+Jaap+van+den+Herik&amp;rft_id=https%3A%2F%2Fdke.maastrichtuniversity.nl%2Fm.winands%2Fdocuments%2FmultithreadedMCTS2.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: Multiple names: authors list (<a href="/wiki/Category:CS1_maint:_Multiple_names:_authors_list" title="Category:CS1 maint: Multiple names: authors list">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
<li id="cite_note-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-47">^</a></b></span> <span class="reference-text"><cite class="citation book">Markus Enzenberger; Martin Müller (2010). <a rel="nofollow" class="external text" href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=02CC0F88A12A3CCE44F0CD139ADA7AF5?doi=10.1.1.161.1984&amp;rep=rep1&amp;type=pdf">"A Lock-free Multithreaded Monte-Carlo Tree Search Algorithm"</a>.  In Jaap Van Den Herik; Pieter Spronck. <i>Advances in Computer Games: 12th International Conference, ACG 2009, Pamplona, Spain, May 11–13, 2009, Revised Papers</i>. Springer. pp.&#160;14–20. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-642-12992-6" title="Special:BookSources/978-3-642-12992-6">978-3-642-12992-6</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=A+Lock-free+Multithreaded+Monte-Carlo+Tree+Search+Algorithm&amp;rft.btitle=Advances+in+Computer+Games%3A+12th+International+Conference%2C+ACG+2009%2C+Pamplona%2C+Spain%2C+May+11%E2%80%9313%2C+2009%2C+Revised+Papers&amp;rft.pages=14-20&amp;rft.pub=Springer&amp;rft.date=2010&amp;rft.isbn=978-3-642-12992-6&amp;rft.au=Markus+Enzenberger&amp;rft.au=Martin+M%C3%BCller&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Bjsessionid%3D02CC0F88A12A3CCE44F0CD139ADA7AF5%3Fdoi%3D10.1.1.161.1984%26rep%3Drep1%26type%3Dpdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></span>
</li>
</ol></div>
<h2><span class="mw-headline" id="Bibliography">Bibliography</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit&amp;section=9" title="Edit section: Bibliography">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><cite class="citation journal">Cameron Browne; Edward Powley; Daniel Whitehouse; Simon Lucas; Peter I. Cowling; Philipp Rohlfshagen; Stephen Tavener; Diego Perez; Spyridon Samothrakis; Simon Colton (March 2012). "A Survey of Monte Carlo Tree Search Methods". <i>IEEE Transactions on Computational Intelligence and AI in Games</i>. <b>4</b> (1): 1–43. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.297.3086">10.1.1.297.3086</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1109%2Ftciaig.2012.2186810">10.1109/tciaig.2012.2186810</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Computational+Intelligence+and+AI+in+Games&amp;rft.atitle=A+Survey+of+Monte+Carlo+Tree+Search+Methods&amp;rft.volume=4&amp;rft.issue=1&amp;rft.pages=1-43&amp;rft.date=2012-03&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.297.3086&amp;rft_id=info%3Adoi%2F10.1109%2Ftciaig.2012.2186810&amp;rft.au=Cameron+Browne&amp;rft.au=Edward+Powley&amp;rft.au=Daniel+Whitehouse&amp;rft.au=Simon+Lucas&amp;rft.au=Peter+I.+Cowling&amp;rft.au=Philipp+Rohlfshagen&amp;rft.au=Stephen+Tavener&amp;rft.au=Diego+Perez&amp;rft.au=Spyridon+Samothrakis&amp;rft.au=Simon+Colton&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMonte+Carlo+tree+search" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r879151008"/></li></ul>

<!-- 
NewPP limit report
Parsed by mw1280
Cached time: 20190213215112
Cache expiry: 2073600
Dynamic content: false
CPU time usage: 0.616 seconds
Real time usage: 0.778 seconds
Preprocessor visited node count: 3014/1000000
Preprocessor generated node count: 0/1500000
Post‐expand include size: 102728/2097152 bytes
Template argument size: 1678/2097152 bytes
Highest expansion depth: 12/40
Expensive parser function count: 7/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 149714/5000000 bytes
Number of Wikibase entities loaded: 5/400
Lua time usage: 0.352/10.000 seconds
Lua memory usage: 5.64 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  622.404      1 -total
 71.16%  442.901      1 Template:Reflist
 31.60%  196.690     13 Template:Cite_journal
 17.92%  111.561     22 Template:Cite_book
  9.34%   58.146      1 Template:Citation_needed
  8.88%   55.259      2 Template:Fix
  7.19%   44.780      1 Template:Infobox_algorithm
  6.57%   40.904      1 Template:Infobox
  6.08%   37.833      4 Template:Category_handler
  5.70%   35.503      9 Template:Cite_web
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:40528449-0!canonical!math=5 and timestamp 20190213215116 and revision id 883198123
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>					<div class="printfooter">
						Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Monte_Carlo_tree_search&amp;oldid=883198123">https://en.wikipedia.org/w/index.php?title=Monte_Carlo_tree_search&amp;oldid=883198123</a>"					</div>
				<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Combinatorial_game_theory" title="Category:Combinatorial game theory">Combinatorial game theory</a></li><li><a href="/wiki/Category:Heuristic_algorithms" title="Category:Heuristic algorithms">Heuristic algorithms</a></li><li><a href="/wiki/Category:Monte_Carlo_methods" title="Category:Monte Carlo methods">Monte Carlo methods</a></li><li><a href="/wiki/Category:Optimal_decisions" title="Category:Optimal decisions">Optimal decisions</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_maint:_Uses_authors_parameter" title="Category:CS1 maint: Uses authors parameter">CS1 maint: Uses authors parameter</a></li><li><a href="/wiki/Category:All_articles_with_dead_external_links" title="Category:All articles with dead external links">All articles with dead external links</a></li><li><a href="/wiki/Category:Articles_with_dead_external_links_from_February_2018" title="Category:Articles with dead external links from February 2018">Articles with dead external links from February 2018</a></li><li><a href="/wiki/Category:Articles_with_permanently_dead_external_links" title="Category:Articles with permanently dead external links">Articles with permanently dead external links</a></li><li><a href="/wiki/Category:CS1_maint:_Multiple_names:_authors_list" title="Category:CS1 maint: Multiple names: authors list">CS1 maint: Multiple names: authors list</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_December_2016" title="Category:Articles with unsourced statements from December 2016">Articles with unsourced statements from December 2016</a></li></ul></div></div>				<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Navigation menu</h2>
			<div id="mw-head">
									<div id="p-personal" role="navigation" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Personal tools</h3>
						<ul>
							<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Monte+Carlo+tree+search" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Monte+Carlo+tree+search" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namespaces</h3>
						<ul>
							<li id="ca-nstab-main" class="selected"><span><a href="/wiki/Monte_Carlo_tree_search" title="View the content page [c]" accesskey="c">Article</a></span></li><li id="ca-talk"><span><a href="/wiki/Talk:Monte_Carlo_tree_search" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></span></li>						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
						<h3 id="p-variants-label">
							<span>Variants</span>
						</h3>
						<ul class="menu">
													</ul>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Views</h3>
						<ul>
							<li id="ca-view" class="collapsible selected"><span><a href="/wiki/Monte_Carlo_tree_search">Read</a></span></li><li id="ca-edit" class="collapsible"><span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></span></li><li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
						<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
						<h3 id="p-cactions-label"><span>More</span></h3>
						<ul class="menu">
													</ul>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Search</label>
						</h3>
						<form action="/w/index.php" id="searchform">
							<div id="simpleSearch">
								<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a></div>
						<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">
			<h3 id="p-navigation-label">Navigation</h3>
			<div class="body">
								<ul>
					<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-interaction" aria-labelledby="p-interaction-label">
			<h3 id="p-interaction-label">Interaction</h3>
			<div class="body">
								<ul>
					<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">
			<h3 id="p-tb-label">Tools</h3>
			<div class="body">
								<ul>
					<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Monte_Carlo_tree_search" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Monte_Carlo_tree_search" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;oldid=883198123" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q11785332" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Monte_Carlo_tree_search&amp;id=883198123" title="Information on how to cite this page">Cite this page</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">
			<h3 id="p-coll-print_export-label">Print/export</h3>
			<div class="body">
								<ul>
					<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Monte+Carlo+tree+search">Create a book</a></li><li id="coll-download-as-rdf2latex"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Monte+Carlo+tree+search&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Monte_Carlo_tree_search&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label">
			<h3 id="p-lang-label">Languages</h3>
			<div class="body">
								<ul>
					<li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/%C3%81rbol_de_b%C3%BAsqueda_Monte_Carlo" title="Árbol de búsqueda Monte Carlo – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%AF%D8%B1%D8%AE%D8%AA_%D8%AC%D8%B3%D8%AA%D8%AC%D9%88%DB%8C_%D9%85%D9%88%D9%86%D8%AA_%DA%A9%D8%A7%D8%B1%D9%84%D9%88" title="درخت جستجوی مونت کارلو – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Recherche_arborescente_Monte-Carlo" title="Recherche arborescente Monte-Carlo – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EB%AA%AC%ED%85%8C%EC%B9%B4%EB%A5%BC%EB%A1%9C_%ED%8A%B8%EB%A6%AC_%ED%83%90%EC%83%89" title="몬테카를로 트리 탐색 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E3%83%A2%E3%83%B3%E3%83%86%E3%82%AB%E3%83%AB%E3%83%AD%E6%9C%A8%E6%8E%A2%E7%B4%A2" title="モンテカルロ木探索 – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Monte-Carlo_Tree_Search" title="Monte-Carlo Tree Search – Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-zh-yue"><a href="https://zh-yue.wikipedia.org/wiki/%E8%92%99%E5%9C%B0%E5%8D%A1%E7%BE%85%E6%A8%B9%E6%90%9C%E7%B4%A2" title="蒙地卡羅樹搜索 – Cantonese" lang="yue" hreflang="yue" class="interlanguage-link-target">粵語</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A0%91%E6%90%9C%E7%B4%A2" title="蒙特卡洛树搜索 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li>				</ul>
				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q11785332#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>			</div>
		</div>
				</div>
		</div>
				<div id="footer" role="contentinfo">
						<ul id="footer-info">
								<li id="footer-info-lastmod"> This page was last edited on 13 February 2019, at 21:51<span class="anonymous-show">&#160;(UTC)</span>.</li>
								<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
							</ul>
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
								<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
								<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
								<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
								<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
								<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
								<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Monte_Carlo_tree_search&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
							</ul>
										<ul id="footer-icons" class="noprint">
										<li id="footer-copyrightico">
						<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>					</li>
										<li id="footer-poweredbyico">
						<a href="//www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>					</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.616","walltime":"0.778","ppvisitednodes":{"value":3014,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":102728,"limit":2097152},"templateargumentsize":{"value":1678,"limit":2097152},"expansiondepth":{"value":12,"limit":40},"expensivefunctioncount":{"value":7,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":149714,"limit":5000000},"entityaccesscount":{"value":5,"limit":400},"timingprofile":["100.00%  622.404      1 -total"," 71.16%  442.901      1 Template:Reflist"," 31.60%  196.690     13 Template:Cite_journal"," 17.92%  111.561     22 Template:Cite_book","  9.34%   58.146      1 Template:Citation_needed","  8.88%   55.259      2 Template:Fix","  7.19%   44.780      1 Template:Infobox_algorithm","  6.57%   40.904      1 Template:Infobox","  6.08%   37.833      4 Template:Category_handler","  5.70%   35.503      9 Template:Cite_web"]},"scribunto":{"limitreport-timeusage":{"value":"0.352","limit":"10.000"},"limitreport-memusage":{"value":5917955,"limit":52428800}},"cachereport":{"origin":"mw1280","timestamp":"20190213215112","ttl":2073600,"transientcontent":false}}});mw.config.set({"wgBackendResponseTime":95,"wgHostname":"mw1244"});});</script>
	</body>
</html>
